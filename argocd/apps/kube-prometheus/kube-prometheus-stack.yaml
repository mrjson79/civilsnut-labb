apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: kube-prometheus-stack
  namespace: argocd
spec:
  project: default
  source:
    chart: kube-prometheus-stack
    repoURL: https://prometheus-community.github.io/helm-charts
    targetRevision: 73.2.0
    helm:
      values: |
        prometheus:
          prometheusSpec:
            serviceMonitorSelector:
              matchLabels:
                release: kube-prometheus-stack
            ruleSelector:
              matchLabels:
                release: kube-prometheus-stack
            additionalScrapeConfigs:
              - job_name: 'cilium-agent-additional'
                kubernetes_sd_configs:
                  - role: pod
                    namespaces:
                      names:
                        - kube-system
                relabel_configs:
                  - source_labels: [__meta_kubernetes_pod_label_k8s_app]
                    action: keep
                    regex: cilium
                  - source_labels: [__address__]
                    action: replace
                    regex: '(.+):(.+)'
                    target_label: __address__
                    replacement: '${1}:9965'
                scrape_interval: 30s
                scrape_timeout: 10s
            walCompression: true
            enableRemoteWriteReceiver: false
            enableAdminAPI: false
            storageSpec:
              volumeClaimTemplate:
                spec:
                  storageClassName: longhorn
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 50Gi
            retention: 10d
            retentionSize: 10GB
            resources:
              requests:
                memory: 2Gi
                cpu: 1000m
              limits:
                memory: 4Gi
                cpu: 2000m
            query:
              maxConcurrency: 20
              maxSamples: 50000000
              timeout: 2m
            nodeSelector:
              has-disk: "yes"

        grafana:
          enabled: true
          persistence:
            enabled: true
            storageClassName: longhorn
            size: 10Gi
            accessModes:
              - ReadWriteMany
          ingress:
            enabled: false
          resources:
            requests:
              memory: 256Mi
              cpu: 100m
            limits:
              memory: 512Mi
              cpu: 200m
          nodeSelector:
            has-disk: "yes"
          downloadDashboards:
            enabled: false
          dashboardProviders:
            dashboardproviders.yaml:
              apiVersion: 1
              providers:
              - name: 'grafana-dashboards-kubernetes'
                orgId: 1
                folder: 'Kubernetes'
                type: file
                disableDeletion: true
                editable: true
                options:
                  path: /var/lib/grafana/dashboards/grafana-dashboards-kubernetes
          dashboards:
            grafana-dashboards-kubernetes:
              k8s-system-api-server:
                url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-system-api-server.json
                token: ''
              k8s-system-coredns:
                url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-system-coredns.json
                token: ''
              k8s-views-global:
                url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-global.json
                token: ''
              k8s-views-namespaces:
                url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-namespaces.json
                token: ''
              k8s-views-nodes:
                url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-nodes.json
                token: ''
              k8s-views-pods:
                url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-pods.json
                token: ''
              # Cilium Dashboards
              cilium-overview:
                url: https://raw.githubusercontent.com/cilium/cilium/main/install/kubernetes/cilium/files/cilium-agent/dashboards/cilium-dashboard.json
                token: ''
              cilium-operator:
                url: https://raw.githubusercontent.com/cilium/cilium/main/install/kubernetes/cilium/files/cilium-operator/dashboards/cilium-operator-dashboard.json
                token: ''
              cilium-hubble:
                url: https://raw.githubusercontent.com/cilium/cilium/main/install/kubernetes/cilium/files/hubble/dashboards/hubble-dashboard.json
                token: ''
              cilium-l7-http:
                url: https://raw.githubusercontent.com/cilium/cilium/main/install/kubernetes/cilium/files/hubble/dashboards/hubble-l7-http-metrics-by-workload.json
                token: ''

        alertmanager:
          alertmanagerSpec:
            storage:
              volumeClaimTemplate:
                spec:
                  storageClassName: longhorn
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 10Gi
            resources:
              requests:
                memory: 256Mi
                cpu: 100m
              limits:
                memory: 512Mi
                cpu: 200m
            nodeSelector:
              has-disk: "yes"

        nodeExporter:
          enabled: true
          resources:
            requests:
              memory: 64Mi
              cpu: 50m
            limits:
              memory: 128Mi
              cpu: 200m

        kubeStateMetrics:
          enabled: true
          metricLabelsAllowlist:
            - "gateways=[*]"
            - "httproutes=[*]"
            - "grpcroutes=[*]"
            - "tcproutes=[*]"
            - "tlsroutes=[*]"
            - "udproutes=[*]"
          extraArgs:
            - --custom-resource-state-config-file=/etc/customresourcestate/gateway-api-crs.yaml
            - --metric-allowlist=kube_gateway.*,kube_httproute.*,kube_grpcroute.*,kube_tcproute.*,kube_tlsroute.*,kube_udproute.*,kube_gatewayclass.*
          volumeMounts:
            - name: gateway-api-crs-config
              mountPath: /etc/customresourcestate
              readOnly: true
          volumes:
            - name: gateway-api-crs-config
              configMap:
                name: gateway-api-crs-config
          resources:
            requests:
              memory: 256Mi
              cpu: 100m
            limits:
              memory: 512Mi
              cpu: 500m

        defaultRules:
          create: true
          rules:
            alertmanager: true
            etcd: true
            configReloaders: true
            general: true
            k8s: true
            kubeApiserver: true
            kubeApiserverAvailability: true
            kubeApiserverSlos: true
            kubelet: true
            kubeProxy: true
            kubePrometheusGeneral: true
            kubePrometheusNodeRecording: true
            kubernetesApps: true
            kubernetesResources: true
            kubernetesStorage: true
            kubernetesSystem: true
            kubeScheduler: true
            kubeStateMetrics: true
            network: true
            node: true
            nodeExporterAlerting: true
            nodeExporterRecording: true
            prometheus: true
            prometheusOperator: true

        global:
          nodeSelector:
            has-disk: "yes"

        prometheusOperator:
          resources:
            requests:
              memory: 256Mi
              cpu: 100m
            limits:
              memory: 512Mi
              cpu: 500m
          prometheusConfigReloader:
            resources:
              requests:
                memory: 64Mi
                cpu: 50m
              limits:
                memory: 128Mi
                cpu: 200m

  destination:
    server: https://kubernetes.default.svc
    namespace: monitoring
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
      allowEmpty: false
    managedNamespaceMetadata:
      labels:
        pod-security.kubernetes.io/enforce: privileged

    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m
