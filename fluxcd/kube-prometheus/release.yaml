apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  interval: 5m
  timeout: 20m
  chart:
    spec:
      chart: kube-prometheus-stack
      version: "79.7.1"
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: monitoring
      interval: 1h
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    remediation:
      retries: 3
  values:
    prometheus:
      prometheusSpec:
        serviceMonitorSelector:
          matchLabels:
            release: kube-prometheus-stack
        ruleSelector:
          matchLabels:
            release: kube-prometheus-stack
        additionalScrapeConfigs:
          - job_name: "cilium-agent-additional"
            kubernetes_sd_configs:
              - role: pod
                namespaces:
                  names:
                    - kube-system
            relabel_configs:
              - source_labels: [__meta_kubernetes_pod_label_k8s_app]
                action: keep
                regex: cilium
              - source_labels: [__address__]
                action: replace
                regex: "(.+):(.+)"
                target_label: __address__
                replacement: "${1}:9965"
            scrape_interval: 30s
            scrape_timeout: 10s
        walCompression: true
        enableRemoteWriteReceiver: false
        enableAdminAPI: false
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: longhorn
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 50Gi
        retention: 10d
        retentionSize: 10GB
        resources:
          requests:
            memory: 2Gi
            cpu: 1000m
          limits:
            memory: 4Gi
            cpu: 2000m
        query:
          maxConcurrency: 20
          maxSamples: 50000000
          timeout: 2m
        nodeSelector:
          has-disk: "yes"

    grafana:
      enabled: true
      persistence:
        enabled: true
        storageClassName: longhorn
        size: 10Gi
        accessModes:
          - ReadWriteMany
      ingress:
        enabled: false
      resources:
        requests:
          memory: 256Mi
          cpu: 100m
        limits:
          memory: 512Mi
          cpu: 200m
      nodeSelector:
        has-disk: "yes"
      downloadDashboards:
        enabled: false
      dashboardProviders:
        dashboardproviders.yaml:
          apiVersion: 1
          providers:
            - name: "grafana-dashboards-kubernetes"
              orgId: 1
              folder: "Kubernetes"
              type: file
              disableDeletion: true
              editable: true
              options:
                path: /var/lib/grafana/dashboards/grafana-dashboards-kubernetes
            - name: "grafana-dashboards-flux"
              orgId: 1
              folder: "FluxCD"
              type: file
              disableDeletion: true
              editable: true
              options:
                path: /var/lib/grafana/dashboards/grafana-dashboards-flux
      dashboards:
        grafana-dashboards-kubernetes:
          k8s-system-api-server:
            url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-system-api-server.json
            token: ""
          k8s-system-coredns:
            url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-system-coredns.json
            token: ""
          k8s-views-global:
            url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-global.json
            token: ""
          k8s-views-namespaces:
            url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-namespaces.json
            token: ""
          k8s-views-nodes:
            url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-nodes.json
            token: ""
          k8s-views-pods:
            url: https://raw.githubusercontent.com/dotdc/grafana-dashboards-kubernetes/master/dashboards/k8s-views-pods.json
            token: ""
          # Cilium Dashboards
          cilium-overview:
            url: https://raw.githubusercontent.com/cilium/cilium/main/install/kubernetes/cilium/files/cilium-agent/dashboards/cilium-dashboard.json
            token: ""
          cilium-operator:
            url: https://raw.githubusercontent.com/cilium/cilium/main/install/kubernetes/cilium/files/cilium-operator/dashboards/cilium-operator-dashboard.json
            token: ""
          cilium-hubble:
            url: https://raw.githubusercontent.com/cilium/cilium/main/install/kubernetes/cilium/files/hubble/dashboards/hubble-dashboard.json
            token: ""
          cilium-l7-http:
            url: https://raw.githubusercontent.com/cilium/cilium/main/install/kubernetes/cilium/files/hubble/dashboards/hubble-l7-http-metrics-by-workload.json
            token: ""
        grafana-dashboards-flux:
          flux-control-plane:
            url: https://raw.githubusercontent.com/fluxcd/flux2-monitoring-example/main/monitoring/configs/dashboards/control-plane.json
            token: ""
          flux-cluster-stats:
            url: https://raw.githubusercontent.com/fluxcd/flux2-monitoring-example/main/monitoring/configs/dashboards/cluster.json
            token: ""

    alertmanager:
      alertmanagerSpec:
        storage:
          volumeClaimTemplate:
            spec:
              storageClassName: longhorn
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 10Gi
        resources:
          requests:
            memory: 256Mi
            cpu: 100m
          limits:
            memory: 512Mi
            cpu: 200m
        nodeSelector:
          has-disk: "yes"

    nodeExporter:
      enabled: true
      resources:
        requests:
          memory: 64Mi
          cpu: 50m
        limits:
          memory: 128Mi
          cpu: 200m

    kubeStateMetrics:
      enabled: true
      metricLabelsAllowlist:
        - "gateways=[*]"
        - "httproutes=[*]"
        - "grpcroutes=[*]"
        - "tcproutes=[*]"
        - "tlsroutes=[*]"
        - "udproutes=[*]"
      rbac:
        extraRules:
          - apiGroups: ["source.toolkit.fluxcd.io"]
            resources:
              [
                "gitrepositories",
                "buckets",
                "helmrepositories",
                "helmcharts",
                "ocirepositories",
              ]
            verbs: ["list", "watch"]
          - apiGroups: ["kustomize.toolkit.fluxcd.io"]
            resources: ["kustomizations"]
            verbs: ["list", "watch"]
          - apiGroups: ["helm.toolkit.fluxcd.io"]
            resources: ["helmreleases"]
            verbs: ["list", "watch"]
          - apiGroups: ["notification.toolkit.fluxcd.io"]
            resources: ["providers", "alerts", "receivers"]
            verbs: ["list", "watch"]
          - apiGroups: ["image.toolkit.fluxcd.io"]
            resources:
              ["imagepolicies", "imagerepositories", "imageupdateautomations"]
            verbs: ["list", "watch"]
      collectors: []
      extraArgs:
        - --custom-resource-state-only=true
        - --custom-resource-state-config-file=/etc/customresourcestate/kube-state-metrics-config.yaml
        - --metric-allowlist=kube_gateway.*,kube_httproute.*,kube_grpcroute.*,kube_tcproute.*,kube_tlsroute.*,kube_udproute.*,kube_gatewayclass.*,gotk_.*
      volumeMounts:
        - name: flux-kube-state-metrics-config
          mountPath: /etc/customresourcestate
          readOnly: true
      volumes:
        - name: flux-kube-state-metrics-config
          configMap:
            name: flux-kube-state-metrics-config
      resources:
        requests:
          memory: 256Mi
          cpu: 100m
        limits:
          memory: 512Mi
          cpu: 500m

    defaultRules:
      create: true
      rules:
        alertmanager: true
        etcd: true
        configReloaders: true
        general: true
        k8s: true
        kubeApiserver: true
        kubeApiserverAvailability: true
        kubeApiserverSlos: true
        kubelet: true
        kubeProxy: true
        kubePrometheusGeneral: true
        kubePrometheusNodeRecording: true
        kubernetesApps: true
        kubernetesResources: true
        kubernetesStorage: true
        kubernetesSystem: true
        kubeScheduler: true
        kubeStateMetrics: true
        network: true
        node: true
        nodeExporterAlerting: true
        nodeExporterRecording: true
        prometheus: true
        prometheusOperator: true

    global:
      nodeSelector:
        has-disk: "yes"

    prometheusOperator:
      resources:
        requests:
          memory: 256Mi
          cpu: 100m
        limits:
          memory: 512Mi
          cpu: 500m
      prometheusConfigReloader:
        resources:
          requests:
            memory: 64Mi
            cpu: 50m
          limits:
            memory: 128Mi
            cpu: 200m
